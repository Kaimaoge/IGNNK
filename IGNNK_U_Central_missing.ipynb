{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook present the performance of kriging in a continuous area in the central US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dingyizhuang/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from torch import nn\n",
    "import geopandas as gp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mlt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import torch\n",
    "import random\n",
    "import copy\n",
    "import scipy.sparse as sp\n",
    "from utils import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from basic_structure import D_GCN, C_GCN, K_GCN,IGNNK\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import heapq\n",
    "plt.rcParams['figure.figsize'] = (20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_census='data/ushcn/tl_2017_us_state/tl_2017_us_state.shp'\n",
    "A,X,_= load_udata()\n",
    "X = X[:,:,:,0]\n",
    "X = X.reshape(1218,120*12)\n",
    "X = X/100\n",
    "capacities = np.max(X,axis=1)\n",
    "X=X.T\n",
    "meta_locations = pd.read_csv('data/ushcn/latlon.csv',header=None, names=['latitude','longitude'])\n",
    "meta_locations = meta_locations.astype('float32')\n",
    "map_us=gp.read_file(url_census,encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.max(meta_locations['longitude'])-np.min(meta_locations['longitude'])\n",
    "h = np.max(meta_locations['latitude'])-np.min(meta_locations['latitude'])\n",
    "lng_cond = (meta_locations['longitude']>(np.min(meta_locations['longitude']) + w/4))&(meta_locations['longitude']<(np.min(meta_locations['longitude']) + w/4*3  ))\n",
    "lat_cond = (meta_locations['latitude']>(np.min(meta_locations['latitude']) + h/4))&(meta_locations['latitude']<(np.min(meta_locations['latitude'])+ h/4*3  ))\n",
    "unknow_set_central = np.where(lng_cond&lat_cond)[0]\n",
    "unknow_set_central = set(unknow_set_central)\n",
    "full_set = set(range(0,X.shape[1]))\n",
    "know_set = full_set - unknow_set_central"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kNN(A_new, test_set, full_set, unknow_set):\n",
    "    know_set = full_set - unknow_set\n",
    "\n",
    "    prediction = np.zeros(test_set.shape)\n",
    "    prediction[:, list(know_set)] = test_set[:, list(know_set)]\n",
    "    \n",
    "    for index in list(unknow_set):\n",
    "        Distance = []\n",
    "        for index_k in list(know_set):\n",
    "            Distance.append(A_new[index, index_k])\n",
    "            min_num_index_list = map(Distance.index, heapq.nlargest(3, Distance))\n",
    "            \n",
    "        for choose in min_num_index_list:\n",
    "            prediction[:, index] = prediction[:, index] + prediction[:, list(know_set)[choose]]/3\n",
    "    output = prediction.copy()\n",
    "    prediction[test_set == 0] = 0\n",
    "    \n",
    "    missing_index = np.ones(np.shape(test_set))\n",
    "    missing_index[:, list(unknow_set)] = 0\n",
    "    \n",
    "    test_mask = 1 - missing_index\n",
    "    test_mask[test_set == 0] = 0\n",
    "    MAE = np.sum(np.abs(prediction - test_set))/np.sum(test_mask)\n",
    "    \n",
    "    RMSE = np.sqrt(np.sum((prediction - test_set)*(prediction - test_set))/np.sum(test_mask)) \n",
    "    MAPE = np.sum(np.abs(prediction - test_set)/(test_set + 1e-5))/np.sum(test_mask)\n",
    "    return MAE, RMSE, MAPE , output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load IGNNK models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5769151531227865 5.12747799165521 1.675010677077662\n",
      "3.711297200952198 5.507727572637243 1.1558151324011128\n"
     ]
    }
   ],
   "source": [
    "# Load IGNNC model for central missing\n",
    "space_dim = 900 # randomly set 50 of them are missing, training with dynamic graph\n",
    "time_dim = 6\n",
    "hidden_dim_s = 100\n",
    "hidden_dim_t = 15\n",
    "rank_s = 20\n",
    "rank_t = 4\n",
    "K=1\n",
    "E_maxvalue = 80\n",
    "STmodel = IGNNK(time_dim,hidden_dim_s,K)\n",
    "\n",
    "params_old = torch.load('model/GCNmodel_udata_carea.pth')\n",
    "params_new = {'GNN1.Theta1':params_old['SC1.Theta1'],\n",
    "              'GNN1.bias':params_old['SC1.bias'],\n",
    "              'GNN2.Theta1':params_old['SC2.Theta1'],\n",
    "              'GNN2.bias':params_old['SC2.bias'],\n",
    "              'GNN3.Theta1':params_old['SC3.Theta1'],\n",
    "              'GNN3.bias':params_old['SC3.bias']} # Keys redefined, does not influece the result\n",
    "STmodel.load_state_dict(params_new)\n",
    "\n",
    "udata_sim = joblib.load('model/udata_sim.joblib')\n",
    "MAE_t, RMSE_t, MAPE_t, udata_ignnk= test_error_cap(STmodel, unknow_set_central, full_set, X, A,time_dim,capacities)\n",
    "MAE, RMSE, MAPE, udata_knn = kNN(udata_sim, X,  full_set, unknow_set_central)\n",
    "print(MAE_t, RMSE_t, MAPE_t)\n",
    "print(MAE, RMSE, MAPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1440, 1218)\n",
      "(1440, 1218)\n",
      "(1440, 1218)\n",
      "(1440, 1218)\n"
     ]
    }
   ],
   "source": [
    "# Load baselines\n",
    "udata_true = X\n",
    "gltl = scipy.io.loadmat('model/gltl_result_udata_miss_area_central519_mu5_sigma0.05.mat')\n",
    "udata_gltl = gltl['sol_cokriging']\n",
    "print(udata_gltl.shape)\n",
    "print(udata_ignnk.shape)\n",
    "print(udata_knn.shape)\n",
    "print(udata_true.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full view of the kriging performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# udata Southwest missing \n",
    "fig,axes = plt.subplots(2,4,figsize = (42,7))\n",
    "lng_div = 0.02\n",
    "lat_div = 0.01\n",
    "crowd = [180,200] #crowd 189 and uncrowd\n",
    "ylbs = ['High','Low']\n",
    "#t_crowd = crowd - split_line1\n",
    "s_known = 80\n",
    "s_unknow = 120\n",
    "x_max = 30 \n",
    "for row in range(2):\n",
    "    for col in range(4):\n",
    "        ax = axes[row,col]\n",
    "        map_us.boundary.plot(ax=ax,color='black')\n",
    "        ax.set_xlim((np.min(meta_locations['longitude'].iloc[list(unknow_set_central)])-lng_div,np.max(meta_locations['longitude'].iloc[list(unknow_set_central)])+lng_div))\n",
    "        ax.set_ylim((np.min(meta_locations['latitude'].iloc[list(unknow_set_central)])-lat_div,np.max(meta_locations['latitude'].iloc[list(unknow_set_central)])+lat_div))\n",
    "#         ax.set_xlim((np.min(meta_locations['longitude'])-lng_div,np.max(meta_locations['longitude'])+lng_div))\n",
    "#         ax.set_ylim((np.min(meta_locations['latitude'])-lat_div,np.max(meta_locations['latitude'])+lat_div))\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        if col == 0:\n",
    "            cax=ax.scatter(meta_locations['longitude'][list(know_set)],meta_locations['latitude'][list(know_set)],s=s_known,cmap=plt.cm.RdYlGn_r, c = udata_true[crowd[row],list(know_set)],\n",
    "              norm=mlt.colors.Normalize(vmin=X.min(), vmax = 20 ),alpha=0.6,label='Known nodes')\n",
    "            cax2=ax.scatter(meta_locations['longitude'][list(unknow_set_central)],meta_locations['latitude'][list(unknow_set_central)],s=s_unknow,cmap=plt.cm.RdYlGn_r,c=udata_true[crowd[row],list(unknow_set_central)],\n",
    "              norm=mlt.colors.Normalize(vmin=X.min(), vmax = 20),alpha=1,marker='*',label = 'Unknown nodes')\n",
    "            ax.set_ylabel(ylbs[row],fontsize=34)\n",
    "            if row == 0:\n",
    "                ax.set_title('True',fontsize = 36)\n",
    "        elif col == 1:\n",
    "            ax.scatter(meta_locations['longitude'][list(know_set)],meta_locations['latitude'][list(know_set)],s=s_known,cmap=plt.cm.RdYlGn_r, c = udata_true[crowd[row],list(know_set)],\n",
    "              norm=mlt.colors.Normalize(vmin=X.min(), vmax = 20),alpha=0.6)\n",
    "            ax.scatter(meta_locations['longitude'][list(unknow_set_central)],meta_locations['latitude'][list(unknow_set_central)],s=s_unknow,cmap=plt.cm.RdYlGn_r,c=udata_ignnc[crowd[row],list(unknow_set_central)],\n",
    "              norm=mlt.colors.Normalize(vmin=X.min(), vmax = 20),alpha=1,marker='*')\n",
    "            if row == 0:\n",
    "                ax.set_title('IGNNK',fontsize = 36)\n",
    "        elif col == 2:\n",
    "            ax.scatter(meta_locations['longitude'][list(know_set)],meta_locations['latitude'][list(know_set)],s=s_known,cmap=plt.cm.RdYlGn_r, c = udata_true[crowd[row],list(know_set)],\n",
    "              norm=mlt.colors.Normalize(vmin=X.min(), vmax = 20),alpha=0.6)\n",
    "            ax.scatter(meta_locations['longitude'][list(unknow_set_central)],meta_locations['latitude'][list(unknow_set_central)],s=s_unknow,cmap=plt.cm.RdYlGn_r,c=udata_knn[crowd[row],list(unknow_set_central)],\n",
    "              norm=mlt.colors.Normalize(vmin=X.min(), vmax = 20),alpha=1,marker='*')\n",
    "            if row == 0:\n",
    "                ax.set_title('kNN',fontsize = 36)\n",
    "        else:\n",
    "            ax.scatter(meta_locations['longitude'][list(know_set)],meta_locations['latitude'][list(know_set)],s=s_known,cmap=plt.cm.RdYlGn_r, c = udata_true[crowd[row],list(know_set)],\n",
    "              norm=mlt.colors.Normalize(vmin=X.min(), vmax = 20),alpha=0.6)\n",
    "            ax.scatter(meta_locations['longitude'][list(unknow_set_central)],meta_locations['latitude'][list(unknow_set_central)],s=s_unknow,cmap=plt.cm.RdYlGn_r,c=udata_gltl[crowd[row],list(unknow_set_central)],\n",
    "              norm=mlt.colors.Normalize(vmin=X.min(), vmax = 20),alpha=1,marker='*')\n",
    "            if row == 0:\n",
    "                ax.set_title('GLTL',fontsize = 36)\n",
    "\n",
    "#ax.legend(fontsize=20)\n",
    "#fig.colorbar(cax,ax=ax)\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(right = 0.87,hspace=0.01,wspace =0.01,bottom=0,top=1)\n",
    "l = 0.87\n",
    "b = 0.03\n",
    "w = 0.01\n",
    "h = 0.77\n",
    "rect = [l,b,w,h] \n",
    "cbar_ax = fig.add_axes(rect) \n",
    "\n",
    "cbar = fig.colorbar(cax, cax=cbar_ax)\n",
    "cbar.ax.tick_params(labelsize=30)\n",
    "\n",
    "plt.figlegend(handles=(cax,cax2),labels=('Known nodes','Unknown nodes'),bbox_to_anchor=(0.97, 1), loc=1, borderaxespad=0.,markerscale =3 ,fontsize = 30)\n",
    "plt.savefig('fig/spatial_miss_area_udata_noon{:}_evening{:}.pdf'.format(crowd[0],crowd[1]))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
