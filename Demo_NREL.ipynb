{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f05c1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import load_nerl_data, get_normalized_adj, get_Laplace, calculate_random_walk_matrix,test_error_cap\n",
    "import random\n",
    "import copy\n",
    "import scipy\n",
    "from scipy.io import loadmat\n",
    "import math\n",
    "import pandas as pd\n",
    "from basic_structure import D_GCN, C_GCN, K_GCN,IGNNK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0788108",
   "metadata": {},
   "source": [
    "Define the parameter for NREL case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16c13dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_o_n_m = 100 #sampled space dimension\n",
    "\n",
    "h = 16 #sampled time dimension\n",
    "\n",
    "z = 100 #hidden dimension for graph convolution\n",
    "\n",
    "K = 1 #If using diffusion convolution, the actual diffusion convolution step is K+1\n",
    "\n",
    "n_m = 30 #number of mask node during training\n",
    "\n",
    "N_u = 30 #target locations, N_u locations will be deleted from the training data\n",
    "\n",
    "Max_episode = 750 #max training episode\n",
    "\n",
    "learning_rate = 0.0001 #the learning_rate for Adam optimizer\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "STmodel = IGNNK(h, z, K)\n",
    "\n",
    "STmodel = torch.load('model/nrel_ignnk_sigmaA_cap_20210621.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120274c5",
   "metadata": {},
   "source": [
    "Load data\n",
    "\n",
    "As we further explored IGNNK, we found that adjacency matrix definition is crucial for the performance of GNN traning. Especially in the definition of sigma in Gaussian kernel based adjacency. Here we use a Gaussian Process based method to find an optimal sigma. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "326fb2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52560, 137) 100.0\n"
     ]
    }
   ],
   "source": [
    "# _, X, files_info = load_nerl_data()\n",
    "X = np.load('data/nrel/nerl_X.npy')\n",
    "files_info = pd.read_pickle('data/nrel/nerl_file_infos.pkl')\n",
    "dist_mx = loadmat('data/nrel/nrel_dist_mx_lonlat.mat')\n",
    "dist_mx = dist_mx['nrel_dist_mx_lonlat']\n",
    "dis = dist_mx/1e3\n",
    "A = np.exp( -0.5* np.power( dis/14 ,2) )\n",
    "\n",
    "# We only use 7:00am to 7:00pm as the target data, because otherwise the 0-values of periods without sunshine will greatly influence the results\n",
    "time_used_base = np.arange(84,228)\n",
    "time_used = np.array([])\n",
    "for i in range(365):\n",
    "    time_used = np.concatenate((time_used,time_used_base + 24*12* i))\n",
    "X=X[:,time_used.astype(np.int)]\n",
    "\n",
    "capacities = np.array(files_info['capacity'])\n",
    "capacities = capacities.astype('float32')\n",
    "E_maxvalue = capacities.max()\n",
    "\n",
    "X = X.transpose()/capacities\n",
    "print(X.shape,E_maxvalue)\n",
    "\n",
    "\n",
    "split_line1 = int(X.shape[0] * 0.7)\n",
    "training_set = X[:split_line1, :]\n",
    "test_set = X[split_line1:, :]  # split the training and test period\n",
    "\n",
    "rand = np.random.RandomState(0) # Fixed random output, just an example when seed = 0.\n",
    "unknow_set = rand.choice(list(range(0,X.shape[1])),N_u,replace=False)\n",
    "unknow_set = set(unknow_set)\n",
    "full_set = set(range(0,X.shape[1]))\n",
    "know_set = full_set - unknow_set\n",
    "training_set_s = training_set[:, list(know_set)]   # get the training data in the sample time period\n",
    "A_s = A[:, list(know_set)][list(know_set), :]      # get the observed adjacent matrix from the full adjacent matrix,\n",
    "                                                   # the adjacent matrix are based on pairwise distance, \n",
    "                                                   # so we need not to construct it for each batch, we just use index to find the dynamic adjacent matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6905bd26",
   "metadata": {},
   "source": [
    "Output the result from the best IGNNK model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3a7057b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model 1.7373738777085028 2.7775878816683157 0.9355863602349819\n"
     ]
    }
   ],
   "source": [
    "MAE_t, RMSE_t, R2_t, nrel_ignnk_res  = test_error_cap(STmodel, unknow_set, full_set,test_set, A,h,capacities)\n",
    "print('Best model', MAE_t, RMSE_t, R2_t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:flow]",
   "language": "python",
   "name": "conda-env-flow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
