{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dingyizhuang/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import load_metr_la_rdata, get_normalized_adj, get_Laplace, calculate_random_walk_matrix,test_error\n",
    "import random\n",
    "import pandas as pd\n",
    "from basic_structure import D_GCN, C_GCN, K_GCN,IGNNK\n",
    "import geopandas as gp\n",
    "import matplotlib as mlt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_o_n_m = 150 #sampled space dimension\n",
    "\n",
    "h = 24 #sampled time dimension\n",
    "\n",
    "z = 100 #hidden dimension for graph convolution\n",
    "\n",
    "K = 1 #If using diffusion convolution, the actual diffusion convolution step is K+1\n",
    "\n",
    "n_m = 50 #number of mask node during training\n",
    "\n",
    "N_u = 50 #target locations, N_u locations will be deleted from the training data\n",
    "\n",
    "Max_episode = 750 #max training episode\n",
    "\n",
    "learning_rate = 0.0001 #the learning_rate for Adam optimizer\n",
    "\n",
    "E_maxvalue = 80 #the max value from experience\n",
    "\n",
    "batch_size = 4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the IGNNK model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "STmodel = IGNNK(h, z, K)  # The graph neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, X = load_metr_la_rdata()\n",
    "\n",
    "split_line1 = int(X.shape[2] * 0.7)\n",
    "\n",
    "training_set = X[:, 0, :split_line1].transpose()\n",
    "\n",
    "test_set = X[:, 0, split_line1:].transpose()       # split the training and test period\n",
    "\n",
    "rand = np.random.RandomState(0) # Fixed random output\n",
    "unknow_set = rand.choice(list(range(0,X.shape[0])),N_u,replace=False)\n",
    "unknow_set = set(unknow_set)\n",
    "full_set = set(range(0,207))        \n",
    "know_set = full_set - unknow_set\n",
    "training_set_s = training_set[:, list(know_set)]   # get the training data in the sample time period\n",
    "A_s = A[:, list(know_set)][list(know_set), :]      # get the observed adjacent matrix from the full adjacent matrix,\n",
    "                                                   # the adjacent matrix are based on pairwise distance, \n",
    "                                                   # so we need not to construct it for each batch, we just use index to find the dynamic adjacent matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the IGNNK model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 13.84669567793819 18.09065091466969 0.33429420171997276\n",
      "50 7.434687994130078 10.72937163415485 0.21100419216241564\n",
      "100 7.275340074150249 10.331726716902873 0.2008214807616224\n",
      "150 7.173291618099564 10.27405100625439 0.19947218307948325\n",
      "200 7.110828071905444 10.265990814157375 0.19836048696586614\n",
      "250 7.167354506677904 10.242227312998402 0.1962963276318442\n",
      "300 6.944404237195023 10.511819861386009 0.20025099067242408\n",
      "350 7.0463039180145755 10.374066579245717 0.19742609791212898\n",
      "400 7.367355070249377 10.37452463395154 0.19899259385495882\n",
      "450 7.039615428947189 10.467115978197576 0.20038392117079312\n",
      "500 7.164775463826685 10.58301737444359 0.20212773553359134\n",
      "550 7.131133934803089 10.522983388914009 0.20105683761925103\n",
      "600 7.198868714207114 10.457280934965986 0.20038424762796703\n",
      "650 7.239995941899663 10.52245184910032 0.2025813393185484\n",
      "700 7.075537221572282 10.408439443846984 0.1983830827341213\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(STmodel.parameters(), lr=learning_rate)\n",
    "RMSE_list = []\n",
    "MAE_list = []\n",
    "MAPE_list = []\n",
    "for epoch in range(Max_episode):\n",
    "    for i in range(training_set.shape[0]//(h * batch_size)):  #using time_length as reference to record test_error\n",
    "        t_random = np.random.randint(0, high=(training_set_s.shape[0] - h), size=batch_size, dtype='l')\n",
    "        know_mask = set(random.sample(range(0,training_set_s.shape[1]),n_o_n_m)) #sample n_o + n_m nodes\n",
    "        feed_batch = []\n",
    "        for j in range(batch_size):\n",
    "            feed_batch.append(training_set_s[t_random[j]: t_random[j] + h, :][:, list(know_mask)]) #generate 8 time batches\n",
    "        \n",
    "        inputs = np.array(feed_batch)\n",
    "        inputs_omask = np.ones(np.shape(inputs))\n",
    "        inputs_omask[inputs == 0] = 0           # We found that there are irregular 0 values for METR-LA, so we treat those 0 values as missing data,\n",
    "                                                # For other datasets, it is not necessary to mask 0 values\n",
    "                                                \n",
    "        missing_index = np.ones((inputs.shape))\n",
    "        for j in range(batch_size):\n",
    "            missing_mask = random.sample(range(0,n_o_n_m),n_m) #Masked locations\n",
    "            missing_index[j, :, missing_mask] = 0\n",
    "            \n",
    "        Mf_inputs = inputs * inputs_omask * missing_index / E_maxvalue #normalize the value according to experience\n",
    "        Mf_inputs = torch.from_numpy(Mf_inputs.astype('float32'))\n",
    "        mask = torch.from_numpy(inputs_omask.astype('float32'))   #The reconstruction errors on irregular 0s are not used for training\n",
    "        \n",
    "        A_dynamic = A_s[list(know_mask), :][:, list(know_mask)]   #Obtain the dynamic adjacent matrix\n",
    "        A_q = torch.from_numpy((calculate_random_walk_matrix(A_dynamic).T).astype('float32'))\n",
    "        A_h = torch.from_numpy((calculate_random_walk_matrix(A_dynamic.T).T).astype('float32'))\n",
    "        \n",
    "        outputs = torch.from_numpy(inputs/E_maxvalue) #The label\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        X_res = STmodel(Mf_inputs, A_q, A_h)  #Obtain the reconstruction\n",
    "        \n",
    "        loss = criterion(X_res*mask, outputs*mask)\n",
    "        loss.backward()\n",
    "        optimizer.step()        #Errors backward\n",
    "    \n",
    "    MAE_t, RMSE_t, MAPE_t, metr_ignnk_res  = test_error(STmodel, unknow_set, test_set, A,E_maxvalue, True)\n",
    "    RMSE_list.append(RMSE_t)\n",
    "    MAE_list.append(MAE_t)\n",
    "    MAPE_list.append(MAPE_t)\n",
    "    if epoch%50 == 0:\n",
    "        print(epoch, MAE_t, RMSE_t, MAPE_t)\n",
    "#torch.save(STmodel.state_dict(), 'model/IGNNK.pth') # Save the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw Learning curves on testing error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.plot(RMSE_list,label='RMSE_on_test_set',linewidth=3.5)\n",
    "ax.set_xlabel('Training Batch (x249)',fontsize=20)\n",
    "ax.set_ylabel('RMSE',fontsize=20)\n",
    "ax.tick_params(axis=\"x\", labelsize=14)\n",
    "ax.tick_params(axis=\"y\", labelsize=14)\n",
    "ax.legend(fontsize=16)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('fig/ignnk_learning_curve_metr-la.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw spatial information of METR-LA kriging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_census='data/metr/Census_Road_2010_shapefile/Census_Road_2010.shp'\n",
    "meta_locations = pd.read_csv('data/metr/graph_sensor_locations.csv')\n",
    "map_metr=gp.read_file(url_census,encoding=\"utf-8\")\n",
    "fig,axes = plt.subplots(2,2,figsize = (10,5))\n",
    "lng_div = 0.01\n",
    "lat_div = 0.01\n",
    "crowd = [127,160] #crowd and uncrowd, in the test time slice\n",
    "ylbs = ['Crowded','Uncrowded']\n",
    "\n",
    "for row in range(2):\n",
    "    for col in range(2):\n",
    "        ax = axes[row,col]\n",
    "        map_metr.plot(ax=ax,color='black')\n",
    "        ax.set_xlim((np.min(meta_locations['longitude'])-lng_div,np.max(meta_locations['longitude'])+lng_div))\n",
    "        ax.set_ylim((np.min(meta_locations['latitude'])-lat_div,np.max(meta_locations['latitude'])+lat_div))\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        if col == 0:\n",
    "            cax=ax.scatter(meta_locations['longitude'][list(know_set)],meta_locations['latitude'][list(know_set)],s=100,cmap=plt.cm.RdYlGn, c = test_set[crowd[row],list(know_set)],\n",
    "              norm=mlt.colors.Normalize(vmin=X.min(), vmax = X.max()),alpha=0.6,label='Known nodes')\n",
    "            cax2=ax.scatter(meta_locations['longitude'][list(unknow_set)],meta_locations['latitude'][list(unknow_set)],s=250,cmap=plt.cm.RdYlGn,c=test_set[crowd[row],list(unknow_set)],\n",
    "              norm=mlt.colors.Normalize(vmin=X.min(), vmax = X.max()),alpha=1,marker='*',label = 'Unknown nodes')\n",
    "            ax.set_ylabel(ylbs[row],fontsize=20)\n",
    "            if row == 0:\n",
    "                ax.set_title('True',fontsize = 18)\n",
    "        else:\n",
    "            ax.scatter(meta_locations['longitude'][list(know_set)],meta_locations['latitude'][list(know_set)],s=100,cmap=plt.cm.RdYlGn, c = test_set[crowd[row],list(know_set)],\n",
    "              norm=mlt.colors.Normalize(vmin=X.min(), vmax = X.max()),alpha=0.6)\n",
    "            ax.scatter(meta_locations['longitude'][list(unknow_set)],meta_locations['latitude'][list(unknow_set)],s=250,cmap=plt.cm.RdYlGn,c=metr_ignnk_res[crowd[row],list(unknow_set)],\n",
    "              norm=mlt.colors.Normalize(vmin=X.min(), vmax = X.max()),alpha=1,marker='*')\n",
    "            if row == 0:\n",
    "                ax.set_title('IGNNK',fontsize = 18)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(right = 0.9,hspace=0,wspace =0,bottom=0,top=1)\n",
    "l = 0.92\n",
    "b = 0.03\n",
    "w = 0.015\n",
    "h = 0.8\n",
    "rect = [l,b,w,h] \n",
    "cbar_ax = fig.add_axes(rect) \n",
    "cbar = fig.colorbar(cax, cax=cbar_ax)\n",
    "cbar.ax.tick_params(labelsize=16)\n",
    "\n",
    "plt.figlegend(handles=(cax,cax2),labels=('Known nodes','Unknown nodes'),bbox_to_anchor=(1.2, 1), loc=1, borderaxespad=0.,fontsize = 16 )\n",
    "plt.savefig('fig/metr_ignnk_spatial_crowd{:}_uncrowd{:}.pdf'.format(crowd[0],crowd[1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw temporal information of METR-LA kriging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize = (16,5))\n",
    "s = int(6400-64 )\n",
    "e = int(s + 24*60/5+1)\n",
    "station = list(unknow_set)[24]\n",
    "ax.plot(test_set[s:e,station],label='True',linewidth=3)\n",
    "ax.plot(metr_ignnk_res[s:e,station],label='IGNNK',linewidth = 3)\n",
    "ax.set_ylabel('mile/h',fontsize=20)\n",
    "ax.tick_params(axis=\"x\", labelsize=14)\n",
    "ax.tick_params(axis=\"y\", labelsize=14)\n",
    "ax.set_xticks(range(0,350,50))\n",
    "ax.set_xticklabels(['0:00\\nMar 3rd','4:00','8:00','12:00','16:00','20:00','0:00\\nMar 4th'])\n",
    "ax.legend(bbox_to_anchor=(1, 1), loc=0, borderaxespad=0,fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig('fig/metr_ignnk_temporal.pdf')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
